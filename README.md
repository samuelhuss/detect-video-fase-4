# ğŸ§  Projeto: DetecÃ§Ã£o de EmoÃ§Ãµes e Atividades em VÃ­deo

Este projeto realiza a **anÃ¡lise automÃ¡tica de emoÃ§Ãµes faciais e atividades fÃ­sicas** (como braÃ§os levantados) em vÃ­deos, utilizando:

- [DeepFace](https://github.com/serengil/deepface) para reconhecimento de emoÃ§Ãµes faciais
- [MediaPipe](https://mediapipe.dev/) para detecÃ§Ã£o de pose e face mesh
- GeraÃ§Ã£o de **vÃ­deo anotado**, **relatÃ³rio textual** e **grÃ¡fico de pizza** com a distribuiÃ§Ã£o emocional
- DetecÃ§Ã£o de **caretas/anomalias** com sequÃªncia mÃ­nima configurÃ¡vel

## ğŸ“‚ Estrutura de SaÃ­da

- `video_anotado.mp4`: vÃ­deo com as emoÃ§Ãµes e atividades anotadas
- `relatorio.txt`: relatÃ³rio com eventos, anomalias e estatÃ­sticas
- `grafico_emocoes.png`: grÃ¡fico com a distribuiÃ§Ã£o de emoÃ§Ãµes detectadas

## ğŸš€ Como Executar

### 1. Entre na pasta do projeto

```bash
cd nome-do-repo
```

### 2. Crie um ambiente virtual (opcional, mas recomendado)

```bash
python -m venv venv
source venv/bin/activate  # ou venv\Scripts\activate no Windows
```

### 3. Instale as dependÃªncias

```bash
pip install -r requirements.txt
```

Ou instale manualmente:

```bash
pip install opencv-python mediapipe deepface matplotlib numpy
```

### 4. Adicione seu vÃ­deo

Coloque o vÃ­deo que deseja analisar na raiz do projeto e atualize o nome no cÃ³digo:

```python
video_path = "nome_do_seu_video.mp4"
```

### 5. Execute o script principal

```bash
python analise_video.py
```

## âš™ï¸ ParÃ¢metros que vocÃª pode ajustar

- `expression_threshold`: nÃºmero mÃ­nimo de frames consecutivos com emoÃ§Ã£o negativa para ser considerada uma "careta"
- `fps`: utilizado para converter frames em tempo estimado (automÃ¡tico a partir do vÃ­deo)

## ğŸ“Š EmoÃ§Ãµes detectadas

O DeepFace identifica as seguintes emoÃ§Ãµes:

- `angry`
- `disgust`
- `fear`
- `happy`
- `sad`
- `surprise`
- `neutral`

As emoÃ§Ãµes negativas (`angry`, `disgust`, `fear`, `surprise`) sÃ£o usadas para detectar caretas.

## ğŸ§ª Exemplo de saÃ­da no relatÃ³rio

```
Atividades detectadas:
 - BraÃ§os levantados (frame 204, tempo 00:06)

DistribuiÃ§Ã£o das emoÃ§Ãµes detectadas:
 - happy: 43.5%
 - neutral: 30.2%
 - sad: 15.8%
 - angry: 10.5%

Anomalias detectadas:
 - Careta detectada dos frames 380 a 389 (de 00:12 atÃ© 00:12)
```

## ğŸ–¼ï¸ Exemplo do grÃ¡fico de emoÃ§Ãµes

![grafico_emocoes.png](grafico_emocoes.png)

## âœ… Requisitos

- Python 3.7+
- OpenCV
- MediaPipe
- DeepFace
- matplotlib
- numpy